{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9cd323e",
   "metadata": {},
   "source": [
    "# Training a Machine Learning Model\n",
    "Training machine learning models to predict FPL player points using engineered features.\n",
    "\n",
    "## Models to train\n",
    "- Random Forest, ensemble of decision trees \n",
    "- Linear Regression, baseline for comparison\n",
    "\n",
    "## Features\n",
    "- rolling_avg_points, player form last 5 games \n",
    "- opponent_difficulty, fixture difficulty (1 -10 scale)\n",
    "- minutes, playing time a player gets (0-90 minutes)\n",
    "\n",
    "## Steps\n",
    "- Load features from 'fpl_features.csv',split the data into two parts 80% training and 20% testing, then test both models on the training data, assess on the test data & compare the performance.\n",
    "\n",
    "## Performance Metrics \n",
    "- MAE (Mean Absolute Error), How far the predictions were off by \n",
    "- RMSE (Root Mean Squared Error), Prediction errors\n",
    "- R^2 Score, How well the model predicts (0-1, higher score is better)\n",
    "\n",
    "## Output\n",
    "Random Forest normally achieves - \n",
    "MAE, 2.0-2.5 points\n",
    "R^2 Score, 0.45-.055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f0014d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for ML training\n",
    "# pandas for data manipulation, numpy for numerical operations\n",
    "# sklearn for machine learning models and evaluation\n",
    "# matplotlib for visualizations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ead538c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10329 records\n",
      "756 players\n",
      "1 to 14 GW\n",
      "   name  gameweek  rolling_avg_points  opponent_difficulty  minutes  \\\n",
      "0  Raya         1                 0.0                  6.9       90   \n",
      "1  Raya         2                 0.0                  6.5       90   \n",
      "2  Raya         3                 0.0                  4.9       90   \n",
      "3  Raya         4                 0.0                  7.9       90   \n",
      "4  Raya         5                 0.0                  1.2       90   \n",
      "\n",
      "   total_points  \n",
      "0            10  \n",
      "1             6  \n",
      "2             2  \n",
      "3             6  \n",
      "4             2  \n"
     ]
    }
   ],
   "source": [
    "# Loading the features that are in the featureengineering.ipynb\n",
    "# rolling averages, opponent difficulty and minutes\n",
    "# these will be used to train the model\n",
    "\n",
    "# reading the csv file that has all the features\n",
    "df = pd.read_csv('fpl_features.csv')\n",
    "\n",
    "# Showing how many records, players & gameweeks were loaded\n",
    "print(f\"{len(df)} records\")\n",
    "print(f\"{df['player_id'].nunique()} players\")\n",
    "print(f\"{df['gameweek'].min()} to {df['gameweek'].max()} GW\")\n",
    "\n",
    "# showing the data loaded properly \n",
    "print(df[['name', 'gameweek', 'rolling_avg_points', 'opponent_difficulty', \n",
    "          'minutes', 'total_points']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "000904a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features (x) ['rolling_avg_points', 'opponent_difficulty', 'minutes']\n",
      "target (y) total points\n",
      "\n",
      "training set: 8263 records (80%)\n",
      "test set: 2066 records (20%)\n"
     ]
    }
   ],
   "source": [
    "# preparing data for machine learning\n",
    "# splitting it into features x and y\n",
    "# removing players who didnt play\n",
    "\n",
    "# features x and y\n",
    "# x - input features (what the moodel learns from)\n",
    "# y - target variable (what the model iis trying to predict)\n",
    "# putting the features into x for the model to learn from\n",
    "features = ['rolling_avg_points', 'opponent_difficulty', 'minutes']\n",
    "x = df[features]\n",
    "y = df['total_points']\n",
    "\n",
    "# showing the features we are using for the model \n",
    "# and the total points\n",
    "print(f\"features (x) {features}\")\n",
    "print(f\"target (y) total points\")\n",
    "\n",
    "# splitting data into two parts training 80% and testing 20%\n",
    "# training set, model learns patterns from this data\n",
    "# testing set, model evaluates on this to test generalization\n",
    "# making the random_state - 42, makes the split reproducible\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\ntraining set: {len(x_train)} records (80%)\")\n",
    "print(f\"test set: {len(x_test)} records (20%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "10ed35e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (mean absolute error):  0.83 points\n",
      "On average, predictions are off by 0.83 points\n",
      "RMSE (root mean squared error): 2.01 points\n",
      "R² Score: 0.315\n",
      "Model shows how well the model predicts points 31.5%\n",
      "Moderate performance, Model explains 31.5% of variance\n",
      "Sample Predictions (Random Forest):\n",
      "   Actual  Predicted  Error\n",
      "0       0        0.0    0.0\n",
      "1       0        0.0    0.0\n",
      "2       1        1.3    0.3\n",
      "3       1        7.1    6.1\n",
      "4       1        1.5    0.5\n",
      "5       2        1.7    0.3\n",
      "6       0        0.0    0.0\n",
      "7       0        0.0    0.0\n",
      "8       0        0.0    0.0\n",
      "9       0        0.0    0.0\n"
     ]
    }
   ],
   "source": [
    "# implementing random forest an ensemble learning method\n",
    "# makes multiple decision trees & averages their predictions\n",
    "# it is good at capturing non-linear relationships\n",
    "# using 100 n_estimators, which is 100 decision trees\n",
    "# random_state=42 for reproducability\n",
    "# n_jobs=1 uses all cpu cores for faster training\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "# fit() trains the model on the training data\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "# predictions on test data\n",
    "# showing how well the model works on unseen data\n",
    "rf_predictions = rf_model.predict(x_test)\n",
    "\n",
    "# showing model performance using standard metrics\n",
    "# MAE (mean absolute error) average prediction error in points\n",
    "# the lower the better, shows the average points it is off by\n",
    "rf_mae = mean_absolute_error(y_test, rf_predictions)\n",
    "print(f\"MAE (mean absolute error):  {rf_mae:.2f} points\")\n",
    "print(f\"On average, predictions are off by {rf_mae:.2f} points\")\n",
    "\n",
    "# RMSE (root mean squared error) penalizes large errors more than mae\n",
    "# the lower the better\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_predictions))\n",
    "print(f\"RMSE (root mean squared error): {rf_rmse:.2f} points\")\n",
    "\n",
    "# R^2 Score, how well the model predicts\n",
    "# 1.0 means perfect predictions, 0.0 means the model is the same as just getting the average\n",
    "# the higher the bettter\n",
    "rf_r2 = r2_score(y_test, rf_predictions)\n",
    "print(f\"R² Score: {rf_r2:.3f}\")\n",
    "print(f\"Model shows how well the model predicts points {rf_r2*100:.1f}%\")\n",
    "\n",
    "# Finding the R² score\n",
    "if rf_r2 > 0.5:\n",
    "    print(f\"Strong performance, Model explains {rf_r2*100:.1f}% of variance\")\n",
    "elif rf_r2 > 0.3:\n",
    "    print(f\"Moderate performance, Model explains {rf_r2*100:.1f}% of variance\")\n",
    "elif rf_r2 > 0:\n",
    "    print(f\"Weak performance, Model explains {rf_r2*100:.1f}% of variance\")\n",
    "else:\n",
    "    print(f\"Poor performance, Model didn't learn (negative R²)\")\n",
    "\n",
    "\n",
    "# showing the predictions to see how close they are \n",
    "print(\"Sample Predictions (Random Forest):\")\n",
    "comparison = pd.DataFrame({\n",
    "    'Actual': y_test[:10].values,\n",
    "    'Predicted': rf_predictions[:10].round(1),\n",
    "    'Error': abs(y_test[:10].values - rf_predictions[:10]).round(1)\n",
    "})\n",
    "print(comparison)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
