{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9cd323e",
   "metadata": {},
   "source": [
    "# Training a Machine Learning Model\n",
    "Training machine learning models to predict FPL player points using engineered features.\n",
    "\n",
    "## Models to train\n",
    "- Random Forest, ensemble of decision trees \n",
    "- Linear Regression, baseline for comparison\n",
    "\n",
    "## Features\n",
    "- rolling_avg_points, player form last 5 games \n",
    "- opponent_difficulty, fixture difficulty (1 -10 scale)\n",
    "- minutes, playing time a player gets (0-90 minutes)\n",
    "\n",
    "## Steps\n",
    "- Load features from 'fpl_features.csv',split the data into two parts 80% training and 20% testing, then test both models on the training data, assess on the test data & compare the performance.\n",
    "\n",
    "## Performance Metrics \n",
    "- MAE (Mean Absolute Error), How far the predictions were off by \n",
    "- RMSE (Root Mean Squared Error), Prediction errors\n",
    "- R^2 Score, How well the model predicts (0-1, higher score is better)\n",
    "\n",
    "## Output\n",
    "Random Forest normally achieves - \n",
    "MAE, 2.0-2.5 points\n",
    "R^2 Score, 0.45-.055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0014d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for ML training\n",
    "# pandas for data manipulation, numpy for numerical operations\n",
    "# sklearn for machine learning models and evaluation\n",
    "# matplotlib for visualizations\n",
    "# pickle to save the machine learning models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ead538c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16559 records\n",
      "799 players\n",
      "1 to 22 GW\n",
      "   name  gameweek  rolling_avg_points  opponent_difficulty  minutes  price  \\\n",
      "0  Raya         1                 0.0                  6.9       90    5.9   \n",
      "1  Raya         2                 0.0                  5.8       90    5.9   \n",
      "2  Raya         3                 0.0                  5.2       90    5.9   \n",
      "3  Raya         4                 0.0                  8.0       90    5.9   \n",
      "4  Raya         5                 0.0                  1.0       90    5.9   \n",
      "\n",
      "   is_home  pos_GK  pos_DEF  pos_MID  pos_FWD  clean_sheets_rolling_avg  \\\n",
      "0        0       1        0        0        0                       0.0   \n",
      "1        1       1        0        0        0                       0.0   \n",
      "2        0       1        0        0        0                       0.0   \n",
      "3        1       1        0        0        0                       0.0   \n",
      "4        1       1        0        0        0                       0.0   \n",
      "\n",
      "   total_points  \n",
      "0            10  \n",
      "1             6  \n",
      "2             2  \n",
      "3             6  \n",
      "4             2  \n"
     ]
    }
   ],
   "source": [
    "# Loading the features that are in the featureengineering.ipynb\n",
    "# rolling averages, opponent difficulty and minutes\n",
    "# is_home, price, position encoding DEF, MID, FWD, GK\n",
    "# clean_sheets_rolling_avg defensive form \n",
    "# these will be used to train the model\n",
    "\n",
    "# Loading the features from the database\n",
    "# connecting to the database\n",
    "conn = sqlite3.connect('fpl_data.db')\n",
    "\n",
    "# reading from the features table\n",
    "df = pd.read_sql_query('SELECT * FROM features', conn)\n",
    "\n",
    "# closing the connection\n",
    "conn.close()\n",
    "\n",
    "# Showing how many records, players & gameweeks were loaded\n",
    "print(f\"{len(df)} records\")\n",
    "print(f\"{df['player_id'].nunique()} players\")\n",
    "print(f\"{df['gameweek'].min()} to {df['gameweek'].max()} GW\")\n",
    "\n",
    "# showing the data loaded properly \n",
    "print(df[['name', 'gameweek', 'rolling_avg_points', 'opponent_difficulty', \n",
    "          'minutes', 'price', 'is_home', 'pos_GK','pos_DEF','pos_MID','pos_FWD','clean_sheets_rolling_avg','total_points']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "000904a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features (x) ['rolling_avg_points', 'opponent_difficulty', 'minutes', 'is_home', 'price', 'pos_GK', 'pos_DEF', 'pos_MID', 'pos_FWD', 'clean_sheets_rolling_avg']\n",
      "target (y) total points\n",
      "\n",
      "training set: 13247 records (80%)\n",
      "test set: 3312 records (20%)\n"
     ]
    }
   ],
   "source": [
    "# preparing data for machine learning\n",
    "# splitting it into features x and y\n",
    "# removing players who didnt play\n",
    "\n",
    "# features x and y\n",
    "# x - input features (what the moodel learns from)\n",
    "# y - target variable (what the model iis trying to predict)\n",
    "# putting the features into x for the model to learn from\n",
    "features = [\n",
    "    'rolling_avg_points',\n",
    "    'opponent_difficulty',\n",
    "    'minutes',\n",
    "    'is_home',\n",
    "    'price',\n",
    "    'pos_GK',\n",
    "    'pos_DEF',\n",
    "    'pos_MID',\n",
    "    'pos_FWD',\n",
    "    'clean_sheets_rolling_avg',\n",
    "    ]\n",
    "X = df[features]\n",
    "y = df['total_points']\n",
    "\n",
    "# showing the features we are using for the model \n",
    "# and the total points\n",
    "print(f\"features (x) {features}\")\n",
    "print(f\"target (y) total points\")\n",
    "\n",
    "# splitting data into two parts training 80% and testing 20%\n",
    "# training set, model learns patterns from this data\n",
    "# testing set, model evaluates on this to test generalization\n",
    "# making the random_state - 42, makes the split reproducible\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\ntraining set: {len(X_train)} records (80%)\")\n",
    "print(f\"test set: {len(X_test)} records (20%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ed35e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (mean absolute error):  0.73 points\n",
      "On average, predictions are off by 0.73 points\n",
      "RMSE (root mean squared error): 1.68 points\n",
      "R² Score: 0.508\n",
      "Model shows how well the model predicts points 50.8%\n",
      "Strong performance, Model explains 50.8% of variance\n",
      "Sample Predictions (Random Forest):\n",
      "   Actual  Predicted  Error\n",
      "0       0        2.9    2.9\n",
      "1       0        0.0    0.0\n",
      "2       0        0.0    0.0\n",
      "3       1        3.7    2.7\n",
      "4       0        0.0    0.0\n",
      "5       2        3.6    1.6\n",
      "6      10        3.7    6.3\n",
      "7       0        0.0    0.0\n",
      "8       8        4.4    3.6\n",
      "9       0        0.0    0.0\n"
     ]
    }
   ],
   "source": [
    "# implementing random forest an ensemble learning method\n",
    "# makes multiple decision trees & averages their predictions\n",
    "# it is good at capturing non-linear relationships\n",
    "# using 50 n_estimators, which is 50 decision trees\n",
    "# max_depth=15 limits how deep each tree can go to prevent overfitting\n",
    "# min_samples_split=50 means a node must have at least 50 samples to split\n",
    "# min_samples_leaf=20 means a leaf node must have at least 20 samples\n",
    "# max_features='sqrt' means each tree considers sqrt(total features) when splitting\n",
    "# random_state=42 for reproducability\n",
    "# n_jobs=1 uses all cpu cores for faster training\n",
    "rf_model = RandomForestRegressor(n_estimators=50, max_depth=15, min_samples_split=50, min_samples_leaf=20, max_features='sqrt', random_state=42, n_jobs=-1)\n",
    "# fit() trains the model on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# predictions on test data\n",
    "# showing how well the model works on unseen data\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# showing model performance using standard metrics\n",
    "# MAE (mean absolute error) average prediction error in points\n",
    "# the lower the better, shows the average points it is off by\n",
    "rf_mae = mean_absolute_error(y_test, rf_predictions)\n",
    "print(f\"MAE (mean absolute error):  {rf_mae:.2f} points\")\n",
    "print(f\"On average, predictions are off by {rf_mae:.2f} points\")\n",
    "\n",
    "# RMSE (root mean squared error) penalizes large errors more than mae\n",
    "# the lower the better\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_predictions))\n",
    "print(f\"RMSE (root mean squared error): {rf_rmse:.2f} points\")\n",
    "\n",
    "# R^2 Score, how well the model predicts\n",
    "# 1.0 means perfect predictions, 0.0 means the model is the same as just getting the average\n",
    "# the higher the bettter\n",
    "rf_r2 = r2_score(y_test, rf_predictions)\n",
    "print(f\"R² Score: {rf_r2:.3f}\")\n",
    "print(f\"Model shows how well the model predicts points {rf_r2*100:.1f}%\")\n",
    "\n",
    "# Finding the R² score\n",
    "if rf_r2 > 0.5:\n",
    "    print(f\"Strong performance, Model explains {rf_r2*100:.1f}% of variance\")\n",
    "elif rf_r2 > 0.3:\n",
    "    print(f\"Moderate performance, Model explains {rf_r2*100:.1f}% of variance\")\n",
    "elif rf_r2 > 0:\n",
    "    print(f\"Weak performance, Model explains {rf_r2*100:.1f}% of variance\")\n",
    "else:\n",
    "    print(f\"Poor performance, Model didn't learn (negative R²)\")\n",
    "\n",
    "\n",
    "# showing the predictions to see how close they are \n",
    "print(\"Sample Predictions (Random Forest):\")\n",
    "comparison = pd.DataFrame({\n",
    "    'Actual': y_test[:10].values,\n",
    "    'Predicted': rf_predictions[:10].round(1),\n",
    "    'Error': abs(y_test[:10].values - rf_predictions[:10]).round(1)\n",
    "})\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7816dc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (mean absolute error):  0.86 points\n",
      "RMSE (root mean squared error): 1.73 points\n",
      "R² Score: 0.483\n",
      "Model shows how well the model predicts points 50.8%\n",
      "\n",
      "Example Predictions (Linear Regression):\n",
      "   Actual  Predicted\n",
      "0       0        2.6\n",
      "1       0       -0.1\n",
      "2       0       -0.1\n",
      "3       1        3.6\n",
      "4       0       -0.0\n",
      "5       2        3.8\n",
      "6      10        3.6\n",
      "7       0       -0.4\n",
      "8       8        4.1\n",
      "9       0        0.1\n"
     ]
    }
   ],
   "source": [
    "# Making a baseline (Linear Regression) to compare ml models to\n",
    "# This model assumes a straight line relationship between \n",
    "# inputs and outputs\n",
    "\n",
    "# training linear regression model\n",
    "# no features needed\n",
    "lr_model = LinearRegression()\n",
    "# fit() finds the best linear equation to fit the data\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# showing how well the model works\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "\n",
    "# showing model performance using standard regression metrics\n",
    "# MAE (mean absolute error) average prediction error in points\n",
    "# the lower the better, shows the average points it is off by\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "print(f\"MAE (mean absolute error):  {lr_mae:.2f} points\")\n",
    "\n",
    "# RMSE (root mean squared error) penalizes large errors more than mae\n",
    "# the lower the better\n",
    "lr_rmse = np.sqrt(mean_squared_error(y_test, lr_predictions))\n",
    "print(f\"RMSE (root mean squared error): {lr_rmse:.2f} points\")\n",
    "\n",
    "# R^2 Score, how well the model predicts\n",
    "# 1.0 means perfect predictions, 0.0 means the model is the same as just getting the average\n",
    "# the higher the bettter\n",
    "lr_r2 = r2_score(y_test, lr_predictions)\n",
    "print(f\"R² Score: {lr_r2:.3f}\")\n",
    "print(f\"Model shows how well the model predicts points {rf_r2*100:.1f}%\")\n",
    "\n",
    "# showing the predictions to see how close they are \n",
    "print(\"\\nExample Predictions (Linear Regression):\")\n",
    "comparison = pd.DataFrame({\n",
    "    'Actual': y_test[:10].values,\n",
    "    'Predicted': lr_predictions[:10].round(1)\n",
    "})\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "36f96628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing Random Forest & Linear Regression\n",
      "            Model      MAE     RMSE  R² Score\n",
      "    Random Forest 0.728185 1.682202  0.508213\n",
      "Linear Regression 0.859767 1.725005  0.482868\n",
      "\n",
      "Best Model (Lowest MAE): Random Forest\n",
      "\n",
      "Feature Importance (Random Forest):\n",
      "                 Feature  Importance\n",
      "                 minutes    0.706403\n",
      "      rolling_avg_points    0.119804\n",
      "                   price    0.076982\n",
      "clean_sheets_rolling_avg    0.044315\n",
      "     opponent_difficulty    0.030676\n",
      "                 is_home    0.007966\n",
      "                 pos_DEF    0.005382\n",
      "                 pos_MID    0.003464\n",
      "                  pos_GK    0.003078\n",
      "                 pos_FWD    0.001931\n",
      "\n",
      "Explanation:\n",
      "minutes: 70.6% importance\n",
      "rolling_avg_points: 12.0% importance\n",
      "price: 7.7% importance\n",
      "clean_sheets_rolling_avg: 4.4% importance\n",
      "opponent_difficulty: 3.1% importance\n",
      "is_home: 0.8% importance\n",
      "pos_DEF: 0.5% importance\n",
      "pos_MID: 0.3% importance\n",
      "pos_GK: 0.3% importance\n",
      "pos_FWD: 0.2% importance\n"
     ]
    }
   ],
   "source": [
    "# Comparing both models to see the best one\n",
    "# The model that has the lowest MAE score is the best\n",
    "# in fpl the average error matters more than then perfect predicition\n",
    "\n",
    "# creating a comparison dataframe/table with all the metrics\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'Linear Regression'],\n",
    "    'MAE': [rf_mae, lr_mae],\n",
    "    'RMSE': [rf_rmse, lr_rmse],\n",
    "    'R² Score': [rf_r2, lr_r2]\n",
    "})\n",
    "\n",
    "# Printing out the comparison dataframe/table\n",
    "print(\"\\nComparing Random Forest & Linear Regression\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Seeing what the best model is, the lowest MAE score\n",
    "# The lower the MAE , the smaller average prediction error\n",
    "bmn = comparison_df.loc[comparison_df['MAE'].idxmin(), 'Model']\n",
    "print(f\"\\nBest Model (Lowest MAE): {bmn}\")\n",
    "\n",
    "# This shows what feature matters the most\n",
    "print(\"\\nFeature Importance (Random Forest):\")\n",
    "# Geting the performance score of each feature\n",
    "# The higher the score th more important they are\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(feature_importance.to_string(index=False))\n",
    "\n",
    "# explaining what the importance of the features\n",
    "print(\"\\nExplanation:\")\n",
    "# for the features in the table show what % of performance each has\n",
    "for idx, row in feature_importance.iterrows():\n",
    "    print(f\"{row['Feature']}: {row['Importance']*100:.1f}% importance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b512112d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using gameweek 22 data for predictions\n",
      "\n",
      "Top 10 players, Actual v Predicted\n",
      "      Player  Form  Opponent_Diff  Minutes  Price  is_Home position  Actual_Points  Predicted_Points\n",
      "     Collins   8.8            4.1       90    5.0        0      DEF              1               2.7\n",
      "    Kelleher   7.6            4.1       90    4.6        0       GK              1               2.7\n",
      "      Schade   7.6            4.1       81    7.2        0      MID              1               3.7\n",
      "      Thiago   7.6            4.1       90    7.2        0      FWD              2               4.0\n",
      "        Rice   7.2            8.0       90    7.4        0      MID              3               5.3\n",
      "      Janelt   7.2            4.1       90    4.9        0      MID              1               3.1\n",
      "Lewis-Potter   7.0            4.1        8    4.9        0      DEF              1               1.1\n",
      "      Garner   7.0            8.0       90    5.2        0      MID              4               4.0\n",
      "    Aaronson   7.0            3.3       90    5.4        1      MID              3               3.7\n",
      "    Bruno G.   7.0           10.0       90    7.2        0      MID              3               5.4\n",
      "\n",
      "Average prediction error. 1.57 points\n"
     ]
    }
   ],
   "source": [
    "# Testing random forest on actual players\n",
    "# Getting the latest gameweek data for realistic testing\n",
    "latest_gw = df['gameweek'].max()\n",
    "print(f\"\\nUsing gameweek {latest_gw} data for predictions\")\n",
    "\n",
    "# getting the top 10 players by their form\n",
    "players = df[df['gameweek'] == latest_gw].nlargest(10, 'rolling_avg_points')\n",
    "\n",
    "# adding the features to the players \n",
    "X_players = players[features]\n",
    "# generating precitions using random forest\n",
    "predictions_rf = rf_model.predict(X_players)\n",
    "\n",
    "# making a predictions dataframe/table to show to actual points v the predicted points  \n",
    "predictions = pd.DataFrame({\n",
    "    'Player': players['name'].values,\n",
    "    'Form': players['rolling_avg_points'].values,\n",
    "    'Opponent_Diff': players['opponent_difficulty'].values,\n",
    "    'Minutes': players['minutes'].values,\n",
    "    'Price': players['price'].values,\n",
    "    'is_Home': players['is_home'].values,\n",
    "    'position': players['position'].values,\n",
    "    'Actual_Points': players['total_points'].values,\n",
    "    'Predicted_Points': predictions_rf.round(1)\n",
    "})\n",
    "\n",
    "# printing out the predictions table of actual points v predicted point\n",
    "print(\"\\nTop 10 players, Actual v Predicted\")\n",
    "print(predictions.to_string(index=False))\n",
    "\n",
    "# calculating thhe average error of these predictions\n",
    "# showing how accurate random forest is on the players\n",
    "predictions['Error'] = abs(predictions['Actual_Points'] - predictions['Predicted_Points'])\n",
    "print(f\"\\nAverage prediction error. {predictions['Error'].mean():.2f} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "11903d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest saved to fpl_predictor_model.pkl\n",
      "Summary of Random Forest saved to model_summary.txt\n"
     ]
    }
   ],
   "source": [
    "# Saving Random Forest using pickle\n",
    "# saving to pickle so can the load the file later to make predictions without retraining\n",
    "model_filename = 'fpl_predictor_model.pkl'\n",
    "# wb to write the file in binary mode\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(rf_model, file)\n",
    "\n",
    "print(f\"Random Forest saved to {model_filename}\")\n",
    "\n",
    "# creating a summary of the ml training\n",
    "summary = f\"\"\"\n",
    "Random Forest\n",
    "Training Date - {pd.Timestamp.now()}\n",
    "\n",
    "Features Used -\n",
    "rolling_avg_points - Player form from the last 5 games\n",
    "opponent_difficulty - Fixture difficulty from a scale of 1-10\n",
    "minutes - How many minutes a player gets from 0 -90 minutes\n",
    "is_home - Whether the player is playing at home (1) or away (0)\n",
    "price - Player price in millions\n",
    "pos_GK, pos_DEF, pos_MID, pos_FWD - One-hot encoding for player positions\n",
    "clean_sheets_rolling_avg - Defensive form from last 5 games\n",
    "\n",
    "Performance Metrics -\n",
    "MAE - {rf_mae:.2f} points\n",
    "RMSE - {rf_rmse:.2f} points\n",
    "R² Score - {rf_r2:.3f}\n",
    "\n",
    "Training Data -\n",
    "- Records: {len(X_train)}\n",
    "- Players: {df['player_id'].nunique()}\n",
    "- Gameweeks: {df['gameweek'].min()} to {df['gameweek'].max()}\n",
    "\"\"\"\n",
    "\n",
    "# saving the summary to a txt file\n",
    "with open('model_summary.txt', 'w') as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(\"Summary of Random Forest saved to model_summary.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "522e52c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL DIAGNOSTIC\n",
      "================================================================================\n",
      "\n",
      "1. FEATURE CORRELATIONS:\n",
      "--------------------------------------------------------------------------------\n",
      "   rolling_avg_points            : r = +0.415\n",
      "   opponent_difficulty           : r = +0.051\n",
      "   minutes                       : r = +0.685\n",
      "   is_home                       : r = +0.036\n",
      "   price                         : r = +0.304\n",
      "   clean_sheets_rolling_avg      : r = +0.322\n",
      "\n",
      "2. MISSING VALUES:\n",
      "--------------------------------------------------------------------------------\n",
      "   ✓ No missing values\n",
      "\n",
      "3. FEATURE STATISTICS:\n",
      "--------------------------------------------------------------------------------\n",
      "rolling_avg_points:\n",
      "   Mean: 0.93\n",
      "   Std:  1.59\n",
      "   Min:  -0.60\n",
      "   Max:  11.80\n",
      "   Non-zero: 6672 (40.3%)\n",
      "\n",
      "opponent_difficulty:\n",
      "   Mean: 6.41\n",
      "   Std:  2.38\n",
      "   Min:  1.00\n",
      "   Max:  10.00\n",
      "   Non-zero: 16559 (100.0%)\n",
      "\n",
      "minutes:\n",
      "   Mean: 26.17\n",
      "   Std:  37.69\n",
      "   Min:  0.00\n",
      "   Max:  90.00\n",
      "   Non-zero: 6666 (40.3%)\n",
      "\n",
      "is_home:\n",
      "   Mean: 0.50\n",
      "   Std:  0.50\n",
      "   Min:  0.00\n",
      "   Max:  1.00\n",
      "   Non-zero: 8282 (50.0%)\n",
      "\n",
      "price:\n",
      "   Mean: 4.93\n",
      "   Std:  1.10\n",
      "   Min:  3.70\n",
      "   Max:  15.10\n",
      "   Non-zero: 16559 (100.0%)\n",
      "\n",
      "pos_GK:\n",
      "   Mean: 0.12\n",
      "   Std:  0.32\n",
      "   Min:  0.00\n",
      "   Max:  1.00\n",
      "   Non-zero: 1908 (11.5%)\n",
      "\n",
      "pos_DEF:\n",
      "   Mean: 0.33\n",
      "   Std:  0.47\n",
      "   Min:  0.00\n",
      "   Max:  1.00\n",
      "   Non-zero: 5464 (33.0%)\n",
      "\n",
      "pos_MID:\n",
      "   Mean: 0.45\n",
      "   Std:  0.50\n",
      "   Min:  0.00\n",
      "   Max:  1.00\n",
      "   Non-zero: 7381 (44.6%)\n",
      "\n",
      "pos_FWD:\n",
      "   Mean: 0.11\n",
      "   Std:  0.31\n",
      "   Min:  0.00\n",
      "   Max:  1.00\n",
      "   Non-zero: 1806 (10.9%)\n",
      "\n",
      "clean_sheets_rolling_avg:\n",
      "   Mean: 0.06\n",
      "   Std:  0.14\n",
      "   Min:  0.00\n",
      "   Max:  0.80\n",
      "   Non-zero: 3206 (19.4%)\n",
      "\n",
      "\n",
      "4. OVERFITTING CHECK:\n",
      "--------------------------------------------------------------------------------\n",
      "Training R²: 0.549\n",
      "Test R²:     0.508\n",
      "Gap:         0.041\n",
      "   ✓ Good generalization\n",
      "\n",
      "5. FEATURE IMPORTANCE:\n",
      "--------------------------------------------------------------------------------\n",
      "                 Feature  Importance\n",
      "                 minutes    0.706403\n",
      "      rolling_avg_points    0.119804\n",
      "                   price    0.076982\n",
      "clean_sheets_rolling_avg    0.044315\n",
      "     opponent_difficulty    0.030676\n",
      "                 is_home    0.007966\n",
      "                 pos_DEF    0.005382\n",
      "                 pos_MID    0.003464\n",
      "                  pos_GK    0.003078\n",
      "                 pos_FWD    0.001931\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL DIAGNOSTIC\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Check feature correlations\n",
    "print(\"\\n1. FEATURE CORRELATIONS:\")\n",
    "print(\"-\"*80)\n",
    "for feature in ['rolling_avg_points', 'opponent_difficulty', 'minutes', \n",
    "                'is_home', 'price', 'clean_sheets_rolling_avg']:\n",
    "    if feature in df.columns:\n",
    "        corr = df[feature].corr(df['total_points'])\n",
    "        print(f\"   {feature:30s}: r = {corr:+.3f}\")\n",
    "\n",
    "# 2. Check missing values\n",
    "print(\"\\n2. MISSING VALUES:\")\n",
    "print(\"-\"*80)\n",
    "missing_found = False\n",
    "for feature in features:\n",
    "    missing = df[feature].isna().sum()\n",
    "    if missing > 0:\n",
    "        print(f\"   {feature}: {missing} ({missing/len(df)*100:.1f}%)\")\n",
    "        missing_found = True\n",
    "if not missing_found:\n",
    "    print(\"   ✓ No missing values\")\n",
    "\n",
    "# 3. Check feature statistics\n",
    "print(\"\\n3. FEATURE STATISTICS:\")\n",
    "print(\"-\"*80)\n",
    "for feature in features:\n",
    "    print(f\"{feature}:\")\n",
    "    print(f\"   Mean: {df[feature].mean():.2f}\")\n",
    "    print(f\"   Std:  {df[feature].std():.2f}\")\n",
    "    print(f\"   Min:  {df[feature].min():.2f}\")\n",
    "    print(f\"   Max:  {df[feature].max():.2f}\")\n",
    "    print(f\"   Non-zero: {(df[feature] != 0).sum()} ({(df[feature] != 0).sum()/len(df)*100:.1f}%)\")\n",
    "    print()\n",
    "\n",
    "# 4. Check training vs test performance\n",
    "print(\"\\n4. OVERFITTING CHECK:\")\n",
    "print(\"-\"*80)\n",
    "train_predictions = rf_model.predict(X_train)\n",
    "train_r2 = r2_score(y_train, train_predictions)\n",
    "test_r2 = r2_score(y_test, rf_predictions)\n",
    "\n",
    "print(f\"Training R²: {train_r2:.3f}\")\n",
    "print(f\"Test R²:     {test_r2:.3f}\")\n",
    "print(f\"Gap:         {train_r2 - test_r2:.3f}\")\n",
    "\n",
    "if train_r2 - test_r2 > 0.1:\n",
    "    print(\"   ⚠ Model is overfitting!\")\n",
    "elif train_r2 - test_r2 > 0.05:\n",
    "    print(\"   + Slight overfitting\")\n",
    "else:\n",
    "    print(\"   ✓ Good generalization\")\n",
    "\n",
    "# 5. Feature importance\n",
    "print(\"\\n5. FEATURE IMPORTANCE:\")\n",
    "print(\"-\"*80)\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "print(importance_df.to_string(index=False))\n",
    "\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
